{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    train_path = \"../../data/FMNIST/FCIFAR_alpha10_train.json\"\n",
    "    test_path = \"../../data/FMNIST/FCIFAR_alpha10_test.json\"\n",
    "    with open(train_path, \"rb\") as f:\n",
    "        train_data = pickle.load(f)\n",
    "    with open(test_path, \"rb\") as f:\n",
    "        test_data = pickle.load(f)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "train_data, test_data = import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "m = 3\n",
    "K = 10\n",
    "d = 28 * 28\n",
    "hidden_unit = 64\n",
    "user_name = [\"f_{0:05d}\".format(n) for n in range(N)]\n",
    "\n",
    "x_test = tf.convert_to_tensor(test_data[\"user_data\"][\"test\"]['x'])\n",
    "y_test = tf.convert_to_tensor(test_data[\"user_data\"][\"test\"]['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train(model, x_train, y_train):\n",
    "    model.fit(x_train, y_train, batch_size=64, epochs=10, validation_split=0.2, \n",
    "              callbacks=[tensorboard_callback], steps_per_epoch=1, verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MLPmodel():\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(d, )),\n",
    "        layers.Dense(64, activation = \"relu\", use_bias=False),\n",
    "        layers.Dense(K, use_bias=False),\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=keras.optimizers.SGD(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )   \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNNmodel():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(6, (5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.Conv2D(16, (5, 5), activation='relu'))\n",
    "    model.summary()\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(120))\n",
    "    model.add(layers.Dense(84, activation='relu'))\n",
    "    model.add(layers.Dense(10))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=keras.optimizers.SGD(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )   \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 28, 28, 6)         456       \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 24, 24, 16)        2416      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2872 (11.22 KB)\n",
      "Trainable params: 2872 (11.22 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 28, 28, 6)         456       \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 24, 24, 16)        2416      \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 120)               1106040   \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1119926 (4.27 MB)\n",
      "Trainable params: 1119926 (4.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[(5, 5, 3, 6), (6,), (5, 5, 6, 16), (16,), (9216, 120), (120,), (120, 84), (84,), (84, 10), (10,)]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# model = get_CNNmodel()\n",
    "# y = model(x_test)\n",
    "\n",
    "# dlist = [w.shape for w in model.get_weights()]\n",
    "# print(dlist)\n",
    "# w_num = len(dlist)\n",
    "# print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 28, 28, 6)         456       \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 24, 24, 16)        2416      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2872 (11.22 KB)\n",
      "Trainable params: 2872 (11.22 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 28, 28, 6)         456       \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 24, 24, 16)        2416      \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 120)               1106040   \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1119926 (4.27 MB)\n",
      "Trainable params: 1119926 (4.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Test loss: 2.2803609371185303\n",
      "Test accuracy: 0.15337499976158142\n",
      "Test loss: 2.26332688331604\n",
      "Test accuracy: 0.18324999511241913\n",
      "Test loss: 2.182069778442383\n",
      "Test accuracy: 0.2396250069141388\n",
      "Test loss: 2.140388250350952\n",
      "Test accuracy: 0.20524999499320984\n",
      "Test loss: 2.1363141536712646\n",
      "Test accuracy: 0.20262500643730164\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global_model = get_CNNmodel()\n",
    "\n",
    "w_num = 10\n",
    "T = 5\n",
    "for t in range(T):\n",
    "    w_agg = dict(zip(list(range(w_num)), [\n",
    "        np.zeros((5, 5, 3, 6)), \n",
    "        np.zeros((6, )), \n",
    "        np.zeros((5, 5, 6, 16)),\n",
    "        np.zeros((16, )),\n",
    "        np.zeros((9216, 120)),\n",
    "        np.zeros((120, )),\n",
    "        np.zeros((120, 84)),\n",
    "        np.zeros((84, )),\n",
    "        np.zeros((84, 10)),\n",
    "        np.zeros((10, )),\n",
    "    ]))\n",
    "    participants_set = np.random.choice(N, m, replace=False)\n",
    "\n",
    "    for n in participants_set:\n",
    "        x_train = tf.convert_to_tensor(train_data[\"user_data\"][user_name[n]]['x'])\n",
    "        y_train = tf.convert_to_tensor(train_data[\"user_data\"][user_name[n]]['y'])\n",
    "\n",
    "        local_model = client_train(global_model, x_train, y_train)\n",
    "        for idx in range(w_num):\n",
    "            w_agg[idx] += local_model.get_weights()[idx]\n",
    "\n",
    "\n",
    "    for idx in range(w_num):     \n",
    "        w_agg[idx] = w_agg[idx]/m   \n",
    "\n",
    "    idx = 0\n",
    "    for layer in global_model.layers:\n",
    "        if layer.name.startswith(\"flatten\"):\n",
    "            continue\n",
    "        global_model.get_layer(layer.name).set_weights([w_agg[idx], w_agg[idx + 1]])\n",
    "        idx += 2\n",
    "        \n",
    "    test_scores = global_model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"Test loss:\", test_scores[0])\n",
    "    print(\"Test accuracy:\", test_scores[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 64) (64, 10)\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "m = 3\n",
    "K = 10\n",
    "d = 28 * 28\n",
    "hidden_unit = 64\n",
    "user_name = [\"f_{0:05d}\".format(n) for n in range(N)]\n",
    "\n",
    "x_test = tf.convert_to_tensor(test_data[\"user_data\"][\"test\"]['x'])\n",
    "y_test = tf.convert_to_tensor(test_data[\"user_data\"][\"test\"]['y'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
